{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grade: /100 pts\n",
    "\n",
    "# Assignment 06: Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dan's notes\n",
    "In this solution I am including some of my own notes on how things are typically done in this setting and to discuss some other issues. Please also refer to the Announcement on OWL about scaling and polynomial feature construction for more discussion.\n",
    "\n",
    "**It is okay if students imported additional packages.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Preprocessing (5 pts)\n",
    "Tasks:\n",
    "* Load the data present in 'footballer_small.csv' using the pandas library and store the loaded data in a dataframe\n",
    "* Drop the variables: 'ID','club','club_logo','flag', 'nationality','photo','potential', 'birth_date'\n",
    "* Dummy code the variables: work_rate_att, work_rate_def, preferred_foot. **Because we are running a regularized model, we do not want to drop the first column**\n",
    "* Get a test data set of size 500 - to make results comparable to solutions, set random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dan's Notes\n",
    "In most regularized models we would drop the first column for any dummy variables derived from categorical variables; in particular, both LinearRegression and Lasso fit an intercept by default so it would be best practice here to drop the column(s) and fit an intercept. By the way, in real statistical software the intercept is not penalized but sklearn penalizes the intercept by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (2500, 48)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>pac</th>\n",
       "      <th>sho</th>\n",
       "      <th>pas</th>\n",
       "      <th>dri</th>\n",
       "      <th>def</th>\n",
       "      <th>phy</th>\n",
       "      <th>international_reputation</th>\n",
       "      <th>skill_moves</th>\n",
       "      <th>weak_foot</th>\n",
       "      <th>crossing</th>\n",
       "      <th>finishing</th>\n",
       "      <th>heading_accuracy</th>\n",
       "      <th>short_passing</th>\n",
       "      <th>volleys</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>curve</th>\n",
       "      <th>free_kick_accuracy</th>\n",
       "      <th>long_passing</th>\n",
       "      <th>ball_control</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>sprint_speed</th>\n",
       "      <th>agility</th>\n",
       "      <th>reactions</th>\n",
       "      <th>balance</th>\n",
       "      <th>shot_power</th>\n",
       "      <th>jumping</th>\n",
       "      <th>stamina</th>\n",
       "      <th>strength</th>\n",
       "      <th>long_shots</th>\n",
       "      <th>aggression</th>\n",
       "      <th>interceptions</th>\n",
       "      <th>positioning</th>\n",
       "      <th>vision</th>\n",
       "      <th>penalties</th>\n",
       "      <th>composure</th>\n",
       "      <th>marking</th>\n",
       "      <th>standing_tackle</th>\n",
       "      <th>work_rate_att_Low</th>\n",
       "      <th>work_rate_att_Medium</th>\n",
       "      <th>work_rate_att_High</th>\n",
       "      <th>work_rate_def_Low</th>\n",
       "      <th>work_rate_def_Medium</th>\n",
       "      <th>work_rate_def_High</th>\n",
       "      <th>preferred_foot_Left</th>\n",
       "      <th>preferred_foot_Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>186.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>65</td>\n",
       "      <td>59</td>\n",
       "      <td>49</td>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>58</td>\n",
       "      <td>68</td>\n",
       "      <td>64</td>\n",
       "      <td>74</td>\n",
       "      <td>66</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>51</td>\n",
       "      <td>70</td>\n",
       "      <td>64</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>69</td>\n",
       "      <td>65</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>194.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>61</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "      <td>45</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>57</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>44</td>\n",
       "      <td>39</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>175.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>85</td>\n",
       "      <td>28</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>22</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>59</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>88</td>\n",
       "      <td>83</td>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>185.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>76</td>\n",
       "      <td>54</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>41</td>\n",
       "      <td>60</td>\n",
       "      <td>64</td>\n",
       "      <td>52</td>\n",
       "      <td>75</td>\n",
       "      <td>59</td>\n",
       "      <td>40</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>78</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>63</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>87</td>\n",
       "      <td>79</td>\n",
       "      <td>74</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>182.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>18</td>\n",
       "      <td>56</td>\n",
       "      <td>28</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height_cm  weight_kg  pac  sho  pas  dri  def  phy  \\\n",
       "0   29      186.0       82.0   70   50   56   61   66   74   \n",
       "1   21      194.0       87.0   61   57   53   61   45   54   \n",
       "2   23      175.0       72.0   85   28   55   62   60   68   \n",
       "3   26      185.0       80.0   76   54   67   73   69   78   \n",
       "4   19      182.0       76.0   47   46   51   50   39   47   \n",
       "\n",
       "   international_reputation  skill_moves  weak_foot  crossing  finishing  \\\n",
       "0                         1            2          3        58         44   \n",
       "1                         1            1          2        15         19   \n",
       "2                         1            2          2        60         22   \n",
       "3                         1            2          3        76         41   \n",
       "4                         1            1          2        14         11   \n",
       "\n",
       "   heading_accuracy  short_passing  volleys  dribbling  curve  \\\n",
       "0                65             59       49         56     48   \n",
       "1                15             25       13         16     16   \n",
       "2                54             58       24         59     30   \n",
       "3                60             64       52         75     59   \n",
       "4                13             26       12         14     11   \n",
       "\n",
       "   free_kick_accuracy  long_passing  ball_control  acceleration  sprint_speed  \\\n",
       "0                  42            58            68            64            74   \n",
       "1                  15            19            18            48            42   \n",
       "2                  35            57            62            88            83   \n",
       "3                  40            73            73            73            78   \n",
       "4                  11            22            15            37            41   \n",
       "\n",
       "   agility  reactions  balance  shot_power  jumping  stamina  strength  \\\n",
       "0       66         62       59          59       80       73        76   \n",
       "1       40         57       33          20       44       39        56   \n",
       "2       70         53       75          43       73       79        65   \n",
       "3       67         68       63          65       70       87        79   \n",
       "4       33         45       43          18       56       28        49   \n",
       "\n",
       "   long_shots  aggression  interceptions  positioning  vision  penalties  \\\n",
       "0          51          70             64           43      52         69   \n",
       "1          14          25             23           12      26         22   \n",
       "2          24          58             52           48      55         31   \n",
       "3          74          67             75           68      68         38   \n",
       "4          12          18             12           12      25         16   \n",
       "\n",
       "   composure  marking  standing_tackle  work_rate_att_Low  \\\n",
       "0         65       63               70                  0   \n",
       "1         22       15               16                  0   \n",
       "2         34       60               67                  0   \n",
       "3         66       66               69                  0   \n",
       "4         38       12               12                  0   \n",
       "\n",
       "   work_rate_att_Medium  work_rate_att_High  work_rate_def_Low  \\\n",
       "0                     1                   0                  0   \n",
       "1                     1                   0                  0   \n",
       "2                     1                   0                  0   \n",
       "3                     1                   0                  0   \n",
       "4                     1                   0                  0   \n",
       "\n",
       "   work_rate_def_Medium  work_rate_def_High  preferred_foot_Left  \\\n",
       "0                     1                   0                    0   \n",
       "1                     1                   0                    0   \n",
       "2                     0                   1                    0   \n",
       "3                     1                   0                    0   \n",
       "4                     1                   0                    0   \n",
       "\n",
       "   preferred_foot_Right  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     1  \n",
       "4                     1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('footballer_small.csv')\n",
    "\n",
    "# Drop the aformentioned columns\n",
    "model_data = df.drop(['ID','club','club_logo','flag', 'nationality','photo','potential', 'birth_date'], axis = 'columns')\n",
    "\n",
    "# In order to get dummies, convert categorical data to categorical type\n",
    "model_data['work_rate_att'] = pd.Categorical(model_data.work_rate_att, categories=['Low','Medium','High'])\n",
    "model_data['work_rate_def'] = pd.Categorical(model_data.work_rate_def, categories=['Low','Medium','High'])\n",
    "model_data['preferred_foot'] = pd.Categorical(model_data.preferred_foot, categories = ['Left','Right'])\n",
    "\n",
    "# Dummies, dropping the first category\n",
    "model_data = pd.get_dummies(model_data, drop_first=False)\n",
    "\n",
    "y = model_data.overall\n",
    "X = model_data.drop('overall', axis = 'columns')\n",
    "\n",
    "# Random state assures that folds are consistent across models\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,\n",
    "                                                y, \n",
    "                                                test_size = 500, \n",
    "                                                random_state = 0)\n",
    "print('Training set size:',Xtrain.shape)\n",
    "\n",
    "df.head()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Building the pipeline that preprocesses the data (10 pts)\n",
    "In order to properly build the regression model, the features need to be standardized so that no feature can dominate others in determining the prediction values due to differences in feature scales. Build the pipeline that preprocesses the feature columns of the training data and create a linear regression model. Plot the data before and after the standardization for the stamina feature. <br>\n",
    "In this question, there is no need to overwrite the training set's values. Create a new variable to include the standardized data. The original training data is needed for future exercises. <br>\n",
    "### Question\n",
    "Make observations about the plot.  \n",
    "### Answer: \n",
    "After standardization, the data is observed to be more centered and most data points are around 0 representing the mean and concentrated within one std from the mean. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'frequency'),\n",
       " Text(0.5, 0, 'stamina'),\n",
       " Text(0.5, 1.0, 'After Standardization')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_pipeline = Pipeline([\n",
    "    ('standardize', StandardScaler()),\n",
    "    ('reg', sk.linear_model.LinearRegression())\n",
    "])\n",
    "\n",
    "standardizer_step = model_pipeline.named_steps['standardize']\n",
    "transformed_X = standardizer_step.fit_transform(Xtrain)\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.subplot(1, 2, 1)\n",
    "ax = sns.distplot(Xtrain.stamina,\n",
    "                 bins=50,\n",
    "                 kde=True,\n",
    "                 color='skyblue',\n",
    "                 hist_kws={\"linewidth\": 15,'alpha':1})\n",
    "ax.set(xlabel='stamina', ylabel='frequency', title=\"Before Standardization\")\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "ax = sns.distplot(transformed_X[:, Xtrain.columns.get_loc(\"stamina\")],\n",
    "                 bins=50,\n",
    "                 kde=True,\n",
    "                 color='skyblue',\n",
    "                 hist_kws={\"linewidth\": 15,'alpha':1})\n",
    "ax.set(xlabel='stamina', ylabel='frequency', title=\"After Standardization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>pac</th>\n",
       "      <th>sho</th>\n",
       "      <th>pas</th>\n",
       "      <th>dri</th>\n",
       "      <th>def</th>\n",
       "      <th>phy</th>\n",
       "      <th>international_reputation</th>\n",
       "      <th>skill_moves</th>\n",
       "      <th>weak_foot</th>\n",
       "      <th>crossing</th>\n",
       "      <th>finishing</th>\n",
       "      <th>heading_accuracy</th>\n",
       "      <th>short_passing</th>\n",
       "      <th>volleys</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>curve</th>\n",
       "      <th>free_kick_accuracy</th>\n",
       "      <th>long_passing</th>\n",
       "      <th>ball_control</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>sprint_speed</th>\n",
       "      <th>agility</th>\n",
       "      <th>reactions</th>\n",
       "      <th>balance</th>\n",
       "      <th>shot_power</th>\n",
       "      <th>jumping</th>\n",
       "      <th>stamina</th>\n",
       "      <th>strength</th>\n",
       "      <th>long_shots</th>\n",
       "      <th>aggression</th>\n",
       "      <th>interceptions</th>\n",
       "      <th>positioning</th>\n",
       "      <th>vision</th>\n",
       "      <th>penalties</th>\n",
       "      <th>composure</th>\n",
       "      <th>marking</th>\n",
       "      <th>standing_tackle</th>\n",
       "      <th>work_rate_att_Low</th>\n",
       "      <th>work_rate_att_Medium</th>\n",
       "      <th>work_rate_att_High</th>\n",
       "      <th>work_rate_def_Low</th>\n",
       "      <th>work_rate_def_Medium</th>\n",
       "      <th>work_rate_def_High</th>\n",
       "      <th>preferred_foot_Left</th>\n",
       "      <th>preferred_foot_Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>20</td>\n",
       "      <td>178.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>61</td>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>59</td>\n",
       "      <td>81</td>\n",
       "      <td>77</td>\n",
       "      <td>70</td>\n",
       "      <td>34</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>21</td>\n",
       "      <td>182.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>76</td>\n",
       "      <td>49</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>55</td>\n",
       "      <td>77</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>67</td>\n",
       "      <td>62</td>\n",
       "      <td>75</td>\n",
       "      <td>69</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>34</td>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>25</td>\n",
       "      <td>187.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>73</td>\n",
       "      <td>78</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "      <td>70</td>\n",
       "      <td>35</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>21</td>\n",
       "      <td>175.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>89</td>\n",
       "      <td>72</td>\n",
       "      <td>66</td>\n",
       "      <td>78</td>\n",
       "      <td>33</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>49</td>\n",
       "      <td>69</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>75</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>78</td>\n",
       "      <td>67</td>\n",
       "      <td>78</td>\n",
       "      <td>74</td>\n",
       "      <td>55</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>71</td>\n",
       "      <td>59</td>\n",
       "      <td>24</td>\n",
       "      <td>72</td>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>19</td>\n",
       "      <td>168.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>69</td>\n",
       "      <td>53</td>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>67</td>\n",
       "      <td>51</td>\n",
       "      <td>66</td>\n",
       "      <td>59</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>81</td>\n",
       "      <td>54</td>\n",
       "      <td>76</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  height_cm  weight_kg  pac  sho  pas  dri  def  phy  \\\n",
       "2858   20      178.0       69.0   61   38   52   54   62   71   \n",
       "723    21      182.0       77.0   80   66   64   76   49   64   \n",
       "1953   25      187.0       76.0   73   78   65   77   43   73   \n",
       "1981   21      175.0       77.0   89   72   66   78   33   63   \n",
       "137    19      168.0       59.0   69   53   59   68   44   48   \n",
       "\n",
       "      international_reputation  skill_moves  weak_foot  crossing  finishing  \\\n",
       "2858                         1            2          2        46         29   \n",
       "723                          1            4          2        63         64   \n",
       "1953                         1            1          2        12         12   \n",
       "1981                         1            3          4        73         74   \n",
       "137                          1            2          4        42         50   \n",
       "\n",
       "      heading_accuracy  short_passing  volleys  dribbling  curve  \\\n",
       "2858                61             61       31         53     35   \n",
       "723                 66             66       55         77     60   \n",
       "1953                18             34       14         11      9   \n",
       "1981                49             69       65         80     57   \n",
       "137                 49             67       51         66     59   \n",
       "\n",
       "      free_kick_accuracy  long_passing  ball_control  acceleration  \\\n",
       "2858                  33            48            51            63   \n",
       "723                   54            65            77            83   \n",
       "1953                  12            35            23            44   \n",
       "1981                  55            55            75            90   \n",
       "137                   52            60            67            77   \n",
       "\n",
       "      sprint_speed  agility  reactions  balance  shot_power  jumping  stamina  \\\n",
       "2858            59       56         62       66          59       81       77   \n",
       "723             78       84         67       62          75       69       73   \n",
       "1953            42       43         77       57          25       70       35   \n",
       "1981            89       78         67       78          74       55       66   \n",
       "137             63       81         54       76          60       57       50   \n",
       "\n",
       "      strength  long_shots  aggression  interceptions  positioning  vision  \\\n",
       "2858        70          34          64             62           47      52   \n",
       "723         70          66          34             52           67      65   \n",
       "1953        55          19          41             13           18      45   \n",
       "1981        64          71          59             24           72      68   \n",
       "137         43          54          55             49           47      65   \n",
       "\n",
       "      penalties  composure  marking  standing_tackle  work_rate_att_Low  \\\n",
       "2858         41         59       62               62                  0   \n",
       "723          67         66       43               48                  0   \n",
       "1953         27         52       14               15                  0   \n",
       "1981         62         68       35               33                  0   \n",
       "137          57         60       42               40                  0   \n",
       "\n",
       "      work_rate_att_Medium  work_rate_att_High  work_rate_def_Low  \\\n",
       "2858                     1                   0                  0   \n",
       "723                      1                   0                  0   \n",
       "1953                     1                   0                  0   \n",
       "1981                     1                   0                  0   \n",
       "137                      0                   1                  0   \n",
       "\n",
       "      work_rate_def_Medium  work_rate_def_High  preferred_foot_Left  \\\n",
       "2858                     1                   0                    0   \n",
       "723                      1                   0                    1   \n",
       "1953                     1                   0                    0   \n",
       "1981                     1                   0                    0   \n",
       "137                      0                   1                    0   \n",
       "\n",
       "      preferred_foot_Right  \n",
       "2858                     1  \n",
       "723                      0  \n",
       "1953                     1  \n",
       "1981                     1  \n",
       "137                      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Creating a Complex feature model using 2-nd Polynomial features (10 pts)\n",
    "In this task, the training data consists of the quadratic terms and 2-way interactions of all features except one of standing_tackle, composure, and marking variable. <br> \n",
    "Create <b> four </b> different training sets:\n",
    "* The first training set includes the quadratic terms and 2-way interactions of all the features. \n",
    "* The second/third/fourth training sets include all the features, their quadratic terms, and their 2-way interactions except the standing_tackle/composure/marking features. <br>\n",
    "\n",
    "#### Hint: \n",
    "For the 2nd/3rd and 4th training sets, create the training sets without the aforementioned features and then apply polynomial expansion to the resultant sets. \n",
    "### Questions:\n",
    "* How many linear terms are in each of the new feature set?\n",
    "* How many squared terms are in each of the new feature set?\n",
    "* How many interaction terms are in each of the new feature set? Give an example of one of the interaction terms. \n",
    "### Answer\n",
    "here are 47/48 columns in our design matrix for the backward feature search purposes.\n",
    "\n",
    "Setting `degree=2` and `interactions_only=False` computes $x_i\\cdot x_j$ for all $i,j=1, \\cdots, 47$ and then adds this to our original design matrix. Note that when $i\\neq j$, the ordering of the terms does not matter. This is a total of\n",
    "\n",
    "* 47/48 linear linear terms\n",
    "\n",
    "* 48x47/2  (49x48/2) interaction terms (this includes the squared terms, If you are interested in knowing how I computed this, read the wikipedia page for \"Triangular Number\".)\n",
    "\n",
    "Totalling 1128 (1176) terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dan's notes\n",
    "sklearn by default creates a column of ones when creating polynomial features. It is more common to allow LinearRegression or Lasso to fit the intercept internally. The column of ones can be removed by passing `include_bias=False` to `PolynomialFeatures()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = sk.preprocessing.PolynomialFeatures(2)\n",
    "\n",
    "Xwithout_standing = Xtrain.drop(['standing_tackle'], axis='columns')\n",
    "Xwithout_standing = poly.fit_transform(Xwithout_standing)\n",
    "\n",
    "Xwithout_composure = Xtrain.drop(['composure'], axis='columns')\n",
    "Xwithout_composure = poly.fit_transform(Xwithout_composure)\n",
    "\n",
    "Xwithout_marking= Xtrain.drop(['marking'], axis='columns')\n",
    "Xwithout_marking = poly.fit_transform(Xwithout_marking)\n",
    "X_new_train = poly.fit_transform(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Evaluating the backward feature search (15 pts)\n",
    "In this question, you have to use the pipeline created in question 2 and apply it to each of the training sets created in question 3. Use 10-fold cross validation to report the validation error on the training set using mean squared error as the metric. <br>\n",
    "Show all the steps of the process and compare and analyze the results using the validation error reported. \n",
    "\n",
    "### Answers:\n",
    "Clearly, the base model that includes all the features is the worst performing model. The best performing model out of the four models is the model that excludes the marking feature and its corresponding quadratic and interacting feature. This means that this feature has contributed to the degradation of the quality of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model 2.9760082093514275\n",
      "model without standing tackle 2.754019621740434\n",
      "model without composure 2.8053428040721986\n",
      "model without marking 2.6967793685598975\n"
     ]
    }
   ],
   "source": [
    "cv_score=cross_val_score(model_pipeline, X_new_train, ytrain, cv=10, scoring='neg_mean_squared_error')\n",
    "print('base model', -cv_score.mean())\n",
    "\n",
    "cv_score=cross_val_score(model_pipeline, Xwithout_standing, ytrain, cv=10, scoring='neg_mean_squared_error')\n",
    "print('model without standing tackle', -cv_score.mean())\n",
    "\n",
    "cv_score=cross_val_score(model_pipeline, Xwithout_composure, ytrain, cv=10, scoring='neg_mean_squared_error')\n",
    "print('model without composure', -cv_score.mean())\n",
    "\n",
    "cv_score=cross_val_score(model_pipeline, Xwithout_marking, ytrain, cv=10, scoring='neg_mean_squared_error')\n",
    "print('model without marking', -cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Applying Ridge Regression (10 pts)\n",
    "Build a pipeline that performs scaling and fits the ridge regression on the data that includes the polynomial expansion of all the features. The penalization parameter of is set to 0.5. Use the pipeline to report the validation error using mean square error metric. Use 10-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7146770020410913\n"
     ]
    }
   ],
   "source": [
    "pip = Pipeline([\n",
    "    ('standardize', StandardScaler()),\n",
    "    ('reg', Ridge(alpha=0.5, fit_intercept=True))\n",
    "])\n",
    "\n",
    "cv_scores = cross_val_score(pip,\n",
    "                           X_new_train,\n",
    "                           ytrain,\n",
    "                           cv=10,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "meancv=-cv_scores.mean()\n",
    "print(meancv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Tune the Ridge coefficient for the 2nd-order model (15 pts)\n",
    "Now use 10-fold CV on the training set to determine a good setting for the regularization coefficient. Perform the search going from $\\lambda = \\exp(-8), \\cdots, \\exp(6)$ in 15 evenly spaced increments on the log scale. Plot the mean squared error as a function of $\\log(\\lambda)$. \n",
    "\n",
    "### Questions: \n",
    "\n",
    "What is the best regularization parameter (actual not approximate)? \n",
    "\n",
    "Why does the error increase as $\\lambda \\rightarrow 0?$  Why does the error increase when $\\lambda \\rightarrow \\infty$?  Answer in terms of the bias variance trade off.\n",
    "\n",
    "### Answer: \n",
    "\n",
    "The best lambda can be found using `gscv.best_params_`. \n",
    "\n",
    "As $\\lambda \\rightarrow 0?$, the model is becoming more variable and so RMSE increases.\n",
    "\n",
    "As $\\lambda \\rightarrow \\infty?$, the model is becoming more biased and so RMSE increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$\\\\log(\\\\lambda)$')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {'reg__alpha': np.exp(np.linspace(-8,6,15))}\n",
    "gscv = GridSearchCV(pip, param_grid=params, cv=10, scoring = 'neg_mean_squared_error', refit=True)\n",
    "gscv.fit(X_new_train, ytrain)\n",
    "\n",
    "results = pd.DataFrame(gscv.cv_results_)\n",
    "\n",
    "plt.scatter( np.linspace(-8, 6,15), -results.mean_test_score)\n",
    "plt.xlabel(r'$\\log(\\lambda)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Test error  (10 pts)\n",
    "Now test how the ridge model, fitted to the whole training set, on how it performs on the test data set. \n",
    "\n",
    "\n",
    "Report the following:\n",
    "\n",
    "* The mean squared error on the test data - along with the 95% confidencen interval, determined with the central limit theorem. \n",
    "* The proportion of the variance explained by your model - along wth a 95% confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dan's notes\n",
    "The intent here is to fit a ridge model using the best $\\lambda$ found in Q6 and then to evaluate the resulting model on the test set.\n",
    "\n",
    "The CI for the mean squared error can be found using CLT/normal approximation or bootstrap.\n",
    "\n",
    "The CI for R^2 can be found by bootstrapping the rows of the test set and computing R^2 for each boostrap sample, and using the approach described in Lesson 04. We also provided an approximate standard error for R^2, but I realized after that is for in-sample R^2 not test R^2, and so is not right. I suspect that it is a little larger than necessary so the CI may be a bit wider than necessary.\n",
    "\n",
    "I would say that for out-of-sample R^2 the bootstrap is probably better than CLT-based in most cases. I would also say that out-of-sample R^2 is rarely used to evaluate models in practice. (Rather, RMSE or MAE are used more often in practice.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error:  1.7057441746269257\n",
      "95% CI:  [1.38183746 2.02965089]\n",
      "Proportion variance predicted (r squared)):  0.9669042125842201\n",
      "95% CI:  [0.95864509 0.97516334]\n"
     ]
    }
   ],
   "source": [
    "X_new_test = poly.fit_transform(Xtest)\n",
    "ypred = gscv.predict(X_new_test)\n",
    "sqerr = (ytest-ypred)**2 \n",
    "test_error = sqerr.mean() \n",
    "test_ci = test_error + 1.96 * np.std(sqerr) / np.sqrt(len(sqerr)) * np.array([-1, 1])\n",
    "\n",
    "print(\"Mean squared error: \",test_error)\n",
    "print(\"95% CI: \",test_ci)\n",
    "\n",
    "ss = (ytest-ytest.mean())**2 \n",
    "rsq = 1 - test_error/ss.mean()\n",
    "\n",
    "# [ Or bootstrap. ]\n",
    "n,k = X_new_test.shape\n",
    "rsqse = np.sqrt((4*rsq*(1-rsq)**2*(n - k - 1)**2)/((n**2-1)*(3+n)))\n",
    "rsqci = rsq + 1.96 * rsqse * np.array([-1,1])\n",
    "\n",
    "print(\"Proportion variance predicted (r squared)): \",rsq)\n",
    "print(\"95% CI: \",rsqci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: Analyzing Ridge Coefficients (15 pts)\n",
    "In this question, you are first required to extract all the coefficients of the standing tackle, composure and marking features from the best model of question 7. After that, calculate the mean of the coefficients of the aforementioned features and analyze the results. Based on these observations, draw conclusions about the results in question 4. \n",
    "### Answers: \n",
    "The average coefficients show that out of the marking, standing tackle, and composure features, marking has the least average coefficients followed by composure and standing tackle. The average coefficients show the weight of each of the features in contributing to the prediction. Accordingly, and based on the results, the least important feature for predicting a player's overall is the marking followed by composure and lastly the standing tackle. <br>\n",
    "According to these observations, a correlation is observed between the coefficient results and the results of the backward feature selection in question 4. \n",
    "The best performing model does not include the marking feature in its feature set which correlates to the lower coefficients of this feature after the ridge regression optimization. The same applies to the other two features. This shows that ridge regression successfully lowered the effect of the marking feature which when excluded contributed to producing the best performing model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dan's notes\n",
    "This approach gives a very rough idea of the \"importance\" of the different features. Because we have averaged coefficients over different features (even if they are the linear and squared terms stemming from the same original feature) that average does not necessarily give a good measure of feature importance. An alternative approach would be to quantify how predictions change when we change each feature by one unit, fixing all other features at some value. This technique is sometimes used in complex models in \"explainable AI\" techniques. (It is used in statistics as well.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "composure 0.017963840171779398\n",
      "standing tackle 0.023687032105547495\n",
      "marking 0.014336846518114189\n"
     ]
    }
   ],
   "source": [
    "all_features = poly.get_feature_names(Xtrain.columns)\n",
    "all_coefs = np.array(gscv.best_estimator_.named_steps['reg'].coef_)\n",
    "all_features = list(all_features)\n",
    "indices_composure = [i for i, x in enumerate(all_features) if \"composure\" in x]\n",
    "indices_std_tackle = [i for i, x in enumerate(all_features) if \"standing_tackle\" in x]\n",
    "indices_marking = [i for i, x in enumerate(all_features) if \"marking\" in x]\n",
    "coefs_composure = all_coefs[indices_composure]\n",
    "coefs_std_tackle = all_coefs[indices_std_tackle]\n",
    "coefs_marking = all_coefs[indices_marking]\n",
    "print('composure',coefs_composure.mean())\n",
    "print('standing tackle',coefs_std_tackle.mean())\n",
    "print('marking',coefs_marking.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9: Lasso Regression (10 pts)\n",
    "Let us assume that you are building a linear regression model using only three features: standing tackle, marking, and composure to predict a player's overall rating. Based on the results of question 8, what do you think will be the features' coefficients while applying the lasso regression optimization? Answer in no more than 5 sentences.\n",
    "\n",
    "### Answer\n",
    "In the grand scheme of things, both lasso and ridge regression shrink the less important features' coefficients to enhance the performance of the linear regression model. The key difference between the two techniques is that lasso regression intrinsically applies feature selection by shrinking feature coefficients to zero which removes some features. The results show that marking feature is the less important feature out of the ones considered, followed by composure feature and lastly the standing tackle feature. With the increase of the $\\lambda$ parameter, the coefficient of the marking feature shrinks to 0, rendering it ineffective in the prediction of the player's overall, then the coefficient of the composure feature shrinks to 0, which leaves the model with a single feature to predict the overall rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
